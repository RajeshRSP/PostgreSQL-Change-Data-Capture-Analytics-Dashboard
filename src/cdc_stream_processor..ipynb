{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2264c1-82ce-4e24-94d0-365265a3ed4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import from_json, col, current_timestamp\n",
    "from pyspark.sql.types import StructType, StructField, StringType\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, LongType\n",
    "import pyspark.sql.functions as F\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8dce12-efaf-46b4-9791-8ac6fb2679a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_spark_session():\n",
    "    \"\"\"\n",
    "    Initializes a SparkSession with specific configurations.\n",
    "\n",
    "    Returns:\n",
    "        SparkSession: Initialized SparkSession object.\n",
    "    \"\"\"\n",
    "\n",
    "    return SparkSession.builder \\\n",
    "        .appName(\"KafkaStreamReader\") \\\n",
    "        .config(\"spark.jars.packages\", <spark-sql-kafka-jarfile-path>) \\\n",
    "        .config(\"spark.local.dir\", <location_to_store_spark>) \\\n",
    "        .getOrCreate()\n",
    "    \n",
    "\n",
    "def define_input_json_schema():\n",
    "    \"\"\"\n",
    "    Defines the schema for input JSON data.\n",
    "\n",
    "    Returns:\n",
    "        StructType: Defined input JSON schema.\n",
    "    \"\"\"\n",
    "\n",
    "    return StructType([\n",
    "        StructField(\"schema\", StructType([\n",
    "            StructField(\"type\", StringType(), nullable=True),\n",
    "            StructField(\"fields\", StructType([\n",
    "                StructField(\"type\", StringType(), nullable=True),\n",
    "                StructField(\"optional\", StringType(), nullable=True),\n",
    "                StructField(\"field\", StringType(), nullable=True)\n",
    "            ]), nullable=True),\n",
    "            StructField(\"optional\", StringType(), nullable=True)\n",
    "        ]), nullable=True),\n",
    "        StructField(\"payload\", StructType([\n",
    "            StructField(\"data\", StringType(), nullable=True)\n",
    "        ]), nullable=True)\n",
    "    ])\n",
    "\n",
    "def extract_table_change_info(df):\n",
    "    \"\"\"\n",
    "    Extracts table change information from DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): Input DataFrame containing JSON data.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: Transformed DataFrame with extracted information.\n",
    "    \"\"\"\n",
    "\n",
    "    pattern = \"table\\s(.*?)\\.(.*?)\\:\\s(.*?)\\:\\s\"\n",
    "    return df.select(from_json(\"value\", json_schema).alias(\"json\")) \\\n",
    "        .select(\"json.payload.data\") \\\n",
    "        .filter(F.regexp_extract(col(\"data\"), pattern, 1) != \"\").filter(F.regexp_extract(col(\"data\"), pattern, 2) != \"\") \\\n",
    "        .select(\n",
    "            current_timestamp().alias(\"timestamp\"),\n",
    "            F.current_date().alias(\"date\"),\n",
    "            F.year(F.current_timestamp()).alias(\"year\"),\n",
    "            F.month(F.current_timestamp()).alias(\"month\"),\n",
    "            F.dayofmonth(F.current_timestamp()).alias(\"day\"),\n",
    "            F.hour(F.current_timestamp()).alias(\"hour\"),\n",
    "            F.minute(F.current_timestamp()).alias(\"minute\"),\n",
    "            \n",
    "            F.regexp_extract(col(\"data\"), pattern, 1).alias(\"schema_name\"),\n",
    "            F.regexp_extract(col(\"data\"), pattern, 2).alias(\"table_name\"),\n",
    "            (F.when(F.regexp_extract(col(\"data\"), pattern, 3) == \"INSERT\", 1).otherwise(0)).alias(\"insert\"),\n",
    "            (F.when(F.regexp_extract(col(\"data\"), pattern, 3) == \"UPDATE\", 1).otherwise(0)).alias(\"update\"),\n",
    "            (F.when(F.regexp_extract(col(\"data\"), pattern, 3) == \"TRUNCATE\", 1).otherwise(0)).alias(\"truncate\"),\n",
    "            (F.when(F.regexp_extract(col(\"data\"), pattern, 3) == \"DELETE\", 1).otherwise(0)).alias(\"delete\") \n",
    "        )\n",
    "    \n",
    "def write_to_parquet(df, epoch_id):\n",
    "    \"\"\"\n",
    "    Writes DataFrame to Parquet file.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): DataFrame to be written.\n",
    "        epoch_id (int): Epoch ID for the current batch.\n",
    "    \"\"\"\n",
    "\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y-%m-%d-%H\")\n",
    "    path = f\"<path_to_storage>/{timestamp}\"\n",
    "    df.write.parquet(path, mode=\"append\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c743c78-cb16-455b-a2f8-ee0b4fe06a02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize SparkSession and define JSON schema\n",
    "spark = initialize_spark_session()\n",
    "json_schema = define_input_json_schema()\n",
    "\n",
    "# Define Kafka parameters\n",
    "kafka_params = {\n",
    "    \"kafka.bootstrap.servers\": \"localhost:9092\",\n",
    "    \"subscribe\": \"<kakfa_topic_name\"\n",
    "}\n",
    "\n",
    "# Read data from Kafka into a DataFrame\n",
    "df = spark \\\n",
    "    .readStream \\\n",
    "    .format(\"kafka\") \\\n",
    "    .options(**kafka_params) \\\n",
    "    .load()\n",
    "\n",
    "# Convert value column to string type\n",
    "df = df.withColumn(\"value\", df[\"value\"].cast(\"string\"))\n",
    "\n",
    "# Extract table change information from DataFrame\n",
    "extracted_df = extract_table_change_info(df)\n",
    "\n",
    "# Write extracted DataFrame to Parquet files\n",
    "query = extracted_df.writeStream \\\n",
    "    .outputMode(\"append\") \\\n",
    "    .foreachBatch(write_to_parquet) \\\n",
    "    .start()\n",
    "\n",
    "# Wait for query to terminate\n",
    "query.awaitTermination()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
